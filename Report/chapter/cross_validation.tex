\chapter{Cross Validation}
\label{chp:crossval}
Cross Validation is one of two resampling methods in Statistical Learning, the other being the Bootstrap which will be covered in the next chapter. As the original dataset is a sample, resampling means taking a sample from the dataset and use that in the learning process. This is done by splitting up the data set in different ways, so that the training is done on varying samples. 

\section{The validation set approach}
In the Validation Set Approach the available set of samples are randomly divided into two parts of approximately equal size. One is the training set and the other is the validation set. The idea is then to fit the model on the training set, and then apply the model to the validation set. The resulting error of the validation set is then used as an estimate of the test error. This error is typically found as the Mean Squared Error. 

\myFigure{validationSetApproach.png}{Splitting data randomly}{fig:valid}{1} 

The concept of randomly splitting the dataset is illustrated in Figure \ref{fig:valid}. The dataset is a series of numbers from 1 to n, and the result is here two almost equally sized parts with the numbers from the original dataset randomly distributed. 

The blue half of the dataset is the training set, meaning the part that the model is fit to, and the orange half is the validation set, meaning the part that the model is applied to, in order to predict observations. 

\subsection{Lab 5.3.1}
In this lab exercise the goal is to use the Validation Set Approach. So as described in the section above the first thing to do is to split the data randomly in two halves. The data used here is the \emph{Auto} dataset, containing a list of car informations. 

\begin{lstlisting}[language=Python, label=lst:lst_valid, caption=Auto dataset randomly split]
data = pd.read_csv('Auto.csv', usecols=range(0, 8), na_values='?',
		parse_dates=True).dropna()

df = pd.DataFrame({'mpg': data['mpg'], 'horsepower':  
		pd.to_numeric(data['horsepower'])})

train, test = train_test_split(df, test_size = 0.5)
\end{lstlisting}

Listing \ref{lst:lst_valid} shows the \emph{Auto} data being first read into the program using the pandas library. Since there are some "?" values that are unusable, these are removed by the \emph{.dropna()} function.

Afterwards a dataframe is created containing the \emph{horsepower} and \emph{mpg} information from the dataset. This dataframe is then split randomly in half by the \emph{train\_test\_split()} function. 

\begin{lstlisting}[language=Python, label=lst:fit_valid, caption=Fit linear regression]
X_train = train[['horsepower']]
X_test = test[['horsepower']]

Y_train = train['mpg']
Y_test = test['mpg']

lm = linear_model.LinearRegression()
lm.fit(X_train, Y_train)
\end{lstlisting}

The train and test sets from Listing \ref{lst:lst_valid} are further used in Listing \ref{lst:fit_valid}. Here the \emph{horsepower} and \emph{mpg} data of the splits are further split into X and Y training and test sets. This is to be able to fit a linear model to the training splits, using \emph{X\_train} as the training data and \emph{Y\_train} as the target values.

\section{Leave-one-out cross validation}


\subsection{Lab 5.3.2}
"Taking cross validation to the extreme. Leave one out - we only test on one data point and train on all other.

HIgh computational costs


\section{K-fold cross-validation}


\subsection{Lab 5.3.3}