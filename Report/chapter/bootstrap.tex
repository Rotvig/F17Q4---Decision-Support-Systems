\chapter{Bootstrap}
\label{chp:boots}

The bootstrap is an extremely powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method.

It can be used to estimate the standard errors of the coefficients from a linear regression fit. This is just a simple example. However, the power of the bootstrap lies in the fact that it easily can be applied to a wide range of statistical learnings methods.

Bootstrap relies on random sampling with replacement. Replacement means that the same observations can occur more than once or maybe not at all in the bootstrap data set.

The reason for doing this is if there is a case where there aren't enough samples. Then bootstrap approach can be used to generate simulated data from the original data set.

%Link til billede: https://www.draw.io/?lightbox=1&highlight=0000ff&edit=_blank&layers=1&nav=1#G0Bw37nIXex8aXSl91SjQ4MjlvNXc
\myFigure{bootstrap_example.PNG}{A graphical example of the bootstrap approach on a small sample containing n = 3 observations}{fig:bootstrap}{0.6}

Figure \ref{fig:bootstrap} illustrates an example of the bootstrap approach on a small sample containing n = 3 observations. Each bootstrap contains n observations. These observations are sampled with replacement from the original data set. Each bootstrap data set is used to obtain an estimate of $\hat{\alpha}$.

With all $\alpha$ values estimated the mean and standard deviation can be estimated too reason about the accuracy of the bootstrap data sets.

\section{Lab 5.3.4}

The goal with lab 5.3.4 is to illustrate the use of bootstrap on the simple example used in Section 5.2\citep{ISLR}. The second task of lab 5.3.4 is to estimate the accuracy of the linear regression model on the \emph{Auto} data set.

\subsection{Estimating the Accuracy of a Statistic of Interest}

The first part of lab 5.3.4 is to use the bootstrap approach on the \emph{Portfolio} data set described in section 5.2\citep{ISLR}.

First of all a function for calculating $\alpha$ is required. The function is shown i Listing \ref{lst:alpha}. The function receives \emph{data} which is a vector with the properties X and Y. The second input is \emph{index} which is used to access the wanted X and Y value in the vector \emph{data}.
With the X and Y value the $\alpha$ can now be calculated and returned.

\begin{lstlisting}[caption={Function for calculating $\alpha$ in python}, label=lst:alpha, mathescape=true]
def alpha(data,index):
	X = data['X'][index]
	Y = data['Y'][index]
	return ((np.var(Y) - np.cov(X,Y)) / (np.var(X) + np.var(Y) - ...
		2*np.cov(X,Y)))[0,1]
\end{lstlisting}

The next step is too bootstrap the \emph{Portfolio} data set.

To perform a bootstrap a second function is needed which is seen in listing \ref{lst:bootstrap}.

\begin{lstlisting}[caption={Bootstrap function in python}, label=lst:bootstrap, mathescape=true]
def boot_python(data, function, num_of_iteration):
	n = data.shape[0]
	idx = np.random.randint(0, n, (num_of_iteration, n))
	stat = np.zeros(num_of_iteration)
	for i in xrange(len(idx)):
		stat[i] = function(data, idx[i])
	return {'Mean': np.mean(stat), 'std. error': np.std(stat)}
\end{lstlisting}

The bootstrap method receives three arguments \emph{data} which is the data that the bootstrap approach should be performed on. The next argument is the function for calculating $\alpha$. The last argument is the number of bootstrap data set that should be created.  

Now everything is set to perform a bootstrap on the \emph{Portfolio} data set with an \emph{num\_of\_iteration} set to 1000. the results are $\hat{\alpha}$ is 0.5834 and the standard error $SE(\hat{\alpha})$ is 0.09102.

\subsection{Estimating the Accuracy of a linear Regression Model}

In the next part of lab 5.3.4 the goal is to asses the variability of the estimates for $\beta_0$ and $\beta_1$, the intercept and slope terms for the linear regression model that uses \emph{horsepower} to predict \emph{mpg} in the \emph{Auto} data set.

First step is to create a function to calculate the intercept and slope, this is seen in listing \ref{lst:boot}. The function \emph{boot} performs a linear regression fit on X and Y. 

\begin{lstlisting}[caption={boot function in python}, label=lst:boot, mathescape=true]
def boot(data, index):
	X = data['horsepower'][index]
	Y = data['mpg'][index]
	slope, intercept, r_value, p_value, std_err = stats.linregress(X,Y)
	return [intercept, slope]
\end{lstlisting}

The next step is to adjust the bootstrap function from the last part. the modified bootstrap function is seen in Listing \ref{lst:bootstrap2}. The modified version is the same function as in Listing \ref{lst:bootstrap}, except the modified function now returns the mean intercept, standard error, mean slope and standard error slope.

\begin{lstlisting}[caption={boot function in python}, label=lst:bootstrap2, mathescape=true]
def boot_python2(data, function, num_of_iteration):
	n = data.shape[0]
	idx = np.random.randint(0, n, (num_of_iteration, n))
	stat = np.zeros((num_of_iteration, 2))
	for i in xrange(len(idx)):
		stat[i] = function(data, idx[i])
	return {'Mean intercept': np.mean(stat[:,1]), 
	'std. error intercept': np.std(stat[:,1]), 
	'Mean slope': np.mean(stat[:,0]), 
	'std. error slope': np.std(stat[:,0])}
\end{lstlisting}

Now the standard errors of 1,000 bootstrap estimates for the intercept and slope can be computed.
The bootstrap estimates for the standard error intercept $SE(\hat{\beta_0})$ is 0.8601 and the standard error slope $SE(\hat{\beta_1})$ is 0.007335.

